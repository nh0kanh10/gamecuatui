"""
Cultivation Agent - AI Agent cho Cultivation Simulator
Enhanced v·ªõi World Bible v√† World Database integration
"""

import os
import json
import time
from typing import Dict, Any, Optional, List
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai
import logging

from schemas import CultivationLLMResponse, CharacterCreationResponse
from world_bible import WorldBible
from world_database import WorldDatabase

logger = logging.getLogger(__name__)

load_dotenv()


class CultivationAgent:
    """
    AI Agent cho Cultivation Simulator
    
    Enhanced v·ªõi:
    - World Bible integration (consistency control)
    - World Database context (sects, techniques, locations)
    - 3-tier Memory context
    - Structured output validation
    """
    
    def __init__(self):
        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GEMINI_API_KEY not found in environment")
        
        genai.configure(api_key=api_key)
        
        # Load World Bible
        self.world_bible = WorldBible.load_from_file("data/world_bible.json")
        if not Path("data/world_bible.json").exists():
            # Create default if not exists
            self.world_bible.save_to_file("data/world_bible.json")
        
        # Load World Database
        self.world_db = WorldDatabase("data")
        
        # Load system instruction
        prompt_path = Path("data/prompts/master.md")
        if prompt_path.exists():
            with open(prompt_path, 'r', encoding='utf-8') as f:
                system_instruction = f.read()
        else:
            system_instruction = self._get_default_system_instruction()
        
        # Enhance system instruction v·ªõi World Bible
        system_instruction = self._enhance_system_instruction(system_instruction)
        
        # Use free tier model by default, can override with GEMINI_MODEL env var
        # Priority: GEMINI_MODEL env var > gemini-1.5-flash (free tier, fast)
        model_name = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
        
        # Fallback chain: prioritize FAST models for real-time gameplay
        fallback_models = [
            model_name,  # Try requested first (gemini-2.5-flash)
            "gemini-2.5-flash",      # Fast, stable (if not already selected)
            "gemini-2.0-flash-001",  # Fast, stable 2.0 version
            "gemini-2.0-flash",      # Fast 2.0 flash
            "gemini-flash-latest",   # Latest fast flash
            "gemini-1.5-flash",      # Fast free tier fallback
        ]
        
        # Remove duplicates while preserving order
        seen = set()
        fallback_models = [m for m in fallback_models if not (m in seen or seen.add(m))]
        
        model_initialized = False
        for model_to_try in fallback_models:
            try:
                self.model = genai.GenerativeModel(
                    model_name=model_to_try,
                    system_instruction=system_instruction,
                    safety_settings=[
                        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
                    ],
                    generation_config={
                        "temperature": 0.7,  # Balanced creativity
                        "top_p": 0.95,      # Nucleus sampling (matches model default)
                        "top_k": 64,        # Top-k sampling (matches gemini-2.5 default)
                        "max_output_tokens": 3072,  # Balanced: enough for complete JSON, still fast
                    }
                )
                logger.info(f"‚úÖ Using Gemini model: {model_to_try}")
                model_initialized = True
                break
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to initialize {model_to_try}: {str(e)[:100]}")
                continue
        
        if not model_initialized:
            raise ValueError("Failed to initialize any Gemini model. Check API key and quota.")
        
        # Initialize rate limiting
        self._last_request_time = 0
    
    def _get_default_system_instruction(self) -> str:
        """Default system instruction n·∫øu kh√¥ng c√≥ file"""
        return """
B·∫°n l√† Cultivation Master, ƒëi·ªÅu khi·ªÉn th·∫ø gi·ªõi tu ti√™n.

Nhi·ªám v·ª•:
- T·∫°o narrative phong ph√∫, s·ªëng ƒë·ªông
- ƒê∆∞a ra 4-6 l·ª±a ch·ªçn cho ng∆∞·ªùi ch∆°i
- Tu√¢n th·ªß World Bible (hard facts)
- S·ª≠ d·ª•ng World Database context (sects, techniques, locations)

Format output: JSON v·ªõi narrative, choices, action_intent, state_updates.
"""
    
    def _enhance_system_instruction(self, base_instruction: str) -> str:
        """Enhance system instruction v·ªõi World Bible"""
        world_bible_text = self.world_bible.get_pre_prompt_text()
        
        enhanced = f"""
{base_instruction}

{world_bible_text}

QUAN TR·ªåNG:
- CH·ªà s·ª≠ d·ª•ng th√¥ng tin t·ª´ World Bible v√† World Database
- KH√îNG b·ªãa ƒë·∫∑t facts v·ªÅ realms, abilities, locations
- N·∫øu kh√¥ng bi·∫øt, tr·∫£ l·ªùi "Kh√¥ng bi·∫øt"
"""
        return enhanced
    
    def process_turn(
        self,
        character_data: Dict[str, Any],
        current_choice: Optional[int] = None,
        memory_context: Optional[str] = None,
        working_memory: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω m·ªôt l∆∞·ª£t ch∆°i
        
        Enhanced v·ªõi:
        - Memory context (3-tier)
        - Working memory (current tasks)
        - World Database context (location, sect, etc.)
        """
        
        age = character_data.get("age", 0)
        
        # Character creation (age 0) uses different prompt
        if age == 0 and current_choice is None:
            return self.process_character_creation(character_data, memory_context, working_memory)
        
        # Build prompt v·ªõi full context
        prompt = self._build_prompt(
            character_data=character_data,
            current_choice=current_choice,
            memory_context=memory_context,
            working_memory=working_memory
        )
        
        # Store prompt for debug
        self._last_prompt = prompt
        self._last_ai_response = None
        self._last_parsed_result = None
        self._last_error = None
        
        # Optimize prompt length if too long (reduce token usage)
        prompt_length = len(prompt)
        if prompt_length > 30000:  # ~7500 tokens (safety limit)
            logger.warning(f"Prompt very long ({prompt_length} chars), truncating memory context...")
            # Truncate memory context if too long
            if memory_context and len(memory_context) > 10000:
                memory_context = memory_context[:10000] + "\n[... memory truncated ...]"
                prompt = self._build_prompt(
                    character_data=character_data,
                    current_choice=current_choice,
                    memory_context=memory_context,
                    working_memory=working_memory
                )
                logger.info(f"Prompt optimized to {len(prompt)} chars")
        
        # Optimize prompt length if too long (reduce token usage)
        prompt_length = len(prompt)
        if prompt_length > 30000:  # ~7500 tokens (safety limit)
            logger.warning(f"Prompt very long ({prompt_length} chars), truncating memory context...")
            # Truncate memory context if too long
            if memory_context and len(memory_context) > 10000:
                memory_context = memory_context[:10000] + "\n[... memory truncated ...]"
                prompt = self._build_prompt(
                    character_data=character_data,
                    current_choice=current_choice,
                    memory_context=memory_context,
                    working_memory=working_memory
                )
                logger.info(f"Prompt optimized to {len(prompt)} chars")
        
        # Check AI cache first (if optimizations available)
        text = None
        if hasattr(self, '_optimizations') and self._optimizations:
            cached_response = self._optimizations.ai_cache.get(prompt)
            if cached_response:
                logger.info("‚úÖ AI cache HIT! Using cached response")
                print(f"‚úÖ Cache HIT! Using cached response (instant!)")
                text = cached_response
        
        # Call AI with retry logic for rate limits (only if not cached)
        if text is None:
            max_retries = 3
            retry_delay = 3  # Start with 3 seconds
            
            for attempt in range(max_retries):
                try:
                    print(f"ü§ñ Calling AI (attempt {attempt + 1}/{max_retries}) with choice: {current_choice}, age: {character_data.get('age')}")
                    print(f"üìã Prompt length: {len(prompt)} chars")
                    if attempt == 0:  # Only print preview on first attempt
                        print(f"üìã Prompt preview (last 500 chars): ...{prompt[-500:]}")
                    
                    response = self.model.generate_content(prompt)
                    text = response.text.strip()
                    break  # Success, exit retry loop
                except Exception as e:
                    error_str = str(e)
                
                # Check if it's a quota/rate limit error
                if "429" in error_str or "ResourceExhausted" in error_str or "quota" in error_str.lower():
                    if attempt < max_retries - 1:
                        # Extract retry delay from error if available
                        import re
                        delay_match = re.search(r'retry in ([\d.]+)s', error_str, re.IGNORECASE)
                        if delay_match:
                            retry_delay = float(delay_match.group(1)) + 1  # Add 1 second buffer
                        else:
                            retry_delay = retry_delay * 2  # Exponential backoff
                        
                        print(f"‚ö†Ô∏è Rate limit/quota exceeded. Waiting {retry_delay:.1f}s before retry {attempt + 2}/{max_retries}...")
                        logger.warning(f"Rate limit error (attempt {attempt + 1}): {error_str[:200]}")
                        import time
                        time.sleep(retry_delay)
                        continue
                    else:
                        # Last attempt failed
                        print(f"‚ùå Rate limit error after {max_retries} attempts. Using fallback response.")
                        logger.error(f"Rate limit error after all retries: {error_str[:500]}")
                        self._last_error = error_str
                        return self._create_fallback_response(character_data)
                else:
                    # Other error, don't retry
                    raise
        
        # If we got here without text, something went wrong
        if text is None:
            print(f"‚ùå Failed to get AI response after {max_retries} attempts. Using fallback.")
            return self._create_fallback_response(character_data)
        
        # Store raw response for debug
        self._last_ai_response = text
        
        # Cache response if optimizations available
        if hasattr(self, '_optimizations') and self._optimizations:
            try:
                self._optimizations.ai_cache.set(prompt, text)
            except Exception as e:
                logger.warning(f"Could not cache AI response: {e}")
        
        # Log raw response for debugging
        print(f"üìù AI Raw Response (first 1000 chars): {text[:1000]}...")
        print(f"üìù AI Raw Response length: {len(text)} chars")
        print(f"üìù AI Raw Response (last 500 chars): ...{text[-500:]}")
        
        # Parse JSON
        try:
            result = self._parse_response(text, character_data)
            
            # Store parsed result for debug
            self._last_parsed_result = result
            
            # Log parsed result
            narrative_preview = result.get('narrative', '')[:200]
            print(f"‚úÖ Parsed result narrative (first 200 chars): {narrative_preview}...")
            print(f"‚úÖ Parsed result narrative length: {len(result.get('narrative', ''))}")
            print(f"‚úÖ Is this fallback? {len(result.get('narrative', '')) == 222 or 'ti·∫øp t·ª•c tu luy·ªán t·∫°i' in result.get('narrative', '')}")
            
            # Verify v·ªõi World Bible
            verification = self.world_bible.verify_output(result)
            if not verification["valid"]:
                print(f"‚ö†Ô∏è World Bible violations: {verification['violations']}")
                if verification.get("corrected"):
                    result = verification["corrected"]
            
            return result
        
        except Exception as e:
            print(f"‚ùå AI Error: {e}")
            import traceback
            error_trace = traceback.format_exc()
            print(f"‚ùå Character data: age={character_data.get('age')}, choice={current_choice}")
            print(f"‚ùå This error will cause fallback response to be used")
            
            # Store error for debug
            self._last_error = f"{str(e)}\n{error_trace}"
            
            logger.error(f"AI Error in process_turn: {str(e)}\n{error_trace}")
            return self._create_fallback_response(character_data)
    
    def _build_prompt(
        self,
        character_data: Dict[str, Any],
        current_choice: Optional[int] = None,
        memory_context: Optional[str] = None,
        working_memory: Optional[str] = None
    ) -> str:
        """Build prompt v·ªõi full context"""
        
        # Character info
        age = character_data.get("age", 0)
        gender = character_data.get("gender", "Unknown")
        talent = character_data.get("talent", "Unknown")
        race = character_data.get("race", "Unknown")
        background = character_data.get("background", "Unknown")
        story = character_data.get("story", "")
        
        # Cultivation info
        cultivation = character_data.get("cultivation", {})
        realm = cultivation.get("realm", "Mortal")
        realm_level = cultivation.get("realm_level", 0)
        
        # Attributes
        attributes = character_data.get("attributes", {})
        from attributes import AttributesComponent
        if attributes:
            attrs = AttributesComponent(**attributes)
            ai_context = attrs.get_ai_context_string()
        else:
            ai_context = "Attributes not available"
        
        # Get physique context and prompt
        physique_context = ""
        physique_id = attributes.get('physique_id') if attributes else None
        if physique_id and hasattr(self, '_game_instance') and self._game_instance:
            try:
                physique_system = getattr(self._game_instance, 'physique_system', None)
                if physique_system:
                    physique_data = physique_system.get_physique(physique_id)
                    if physique_data:
                        physique_name = physique_data.get('name', '')
                        physique_desc = physique_data.get('description', '')
                        physique_prompt = physique_system.get_ai_prompt(physique_id)
                        forbidden_words = physique_system.get_forbidden_words(physique_id)
                        
                        physique_context = f"""
Th·ªÉ Ch·∫•t: {physique_name}
M√¥ t·∫£: {physique_desc}

‚ö†Ô∏è QUAN TR·ªåNG - PROMPT CHO TH·ªÇ CH·∫§T:
{physique_prompt}
"""
                        if forbidden_words:
                            physique_context += f"\n‚ùå KH√îNG ƒê∆Ø·ª¢C d√πng c√°c t·ª´: {', '.join(forbidden_words)}"
            except Exception as e:
                logger.warning(f"Error getting physique context: {e}")
        
        if not physique_context:
            physique_context = "Kh√¥ng c√≥ th·ªÉ ch·∫•t ƒë·∫∑c bi·ªát"
        
        # Location context t·ª´ World Database
        location_id = character_data.get("location_id")
        location_context = ""
        if location_id:
            location = self.world_db.get_location(location_id)
            if location:
                # Get regional culture
                culture = self.world_db.get_culture_by_location(location_id)
                culture_info = ""
                if culture:
                    culture_info = f"""
VƒÉn h√≥a v√πng: {culture.get('name', 'Unknown')} - {culture.get('vibe', 'Unknown')}
Quy t·∫Øc x√£ h·ªôi: {json.dumps(culture.get('social_rules', {}), ensure_ascii=False)}
ƒê·∫∑c ƒëi·ªÉm vƒÉn h√≥a: {', '.join([t.get('effect', '') for t in culture.get('cultural_traits', [])[:3]])}
"""
                
                location_context = f"""
ƒê·ªãa ƒëi·ªÉm: {location['name']} ({location.get('region', 'Unknown')})
Lo·∫°i: {location.get('type', 'Unknown')}
M·∫≠t ƒë·ªô linh kh√≠: {location.get('qi_density', 1.0)}x
D·ªãch v·ª•: {', '.join(location.get('services', []))}
Nguy hi·ªÉm: {location.get('danger_level', 'Unknown')}
K·∫øt n·ªëi: {', '.join([self.world_db.get_location(lid).get('name', lid) for lid in location.get('connected_to', []) if self.world_db.get_location(lid)])}
{culture_info}
"""
        
        # Sect context t·ª´ World Database
        sect_id = character_data.get("sect_id")
        sect_context = character_data.get("sect_context", "")
        if not sect_context and sect_id:
            sect = self.world_db.get_sect(sect_id)
            if sect:
                sect_context = f"""
T√¥ng m√¥n: {sect['name']} ({sect.get('type', 'Unknown')})
Tri·∫øt l√Ω: {sect.get('description', '')}
K·ªπ thu·∫≠t ƒë·ªôc quy·ªÅn: {', '.join(sect.get('exclusive_techniques', []))}
Y√™u c·∫ßu: {json.dumps(sect.get('requirements', {}), ensure_ascii=False)}
"""
        
        # Race context t·ª´ World Database
        race_id = character_data.get("race")
        race_context = ""
        if race_id:
            race = self.world_db.get_race(race_id)
            if race:
                race_context = f"""
Ch·ªßng t·ªôc: {race.get('name', race_id)}
M√¥ t·∫£: {race.get('description', '')}
ƒê·∫∑c ƒëi·ªÉm: {', '.join(race.get('traits', []))}
"""
        
        # Get talent AI effect if available
        talent_ai_effect = ""
        try:
            import json
            from pathlib import Path
            talents_path = Path("data/talents_ai_friendly.json")
            if talents_path.exists():
                with open(talents_path, 'r', encoding='utf-8') as f:
                    talents_list = json.load(f)
                    for t in talents_list:
                        if t.get('name') == talent:
                            talent_ai_effect = t.get('ai_effect', '')
                            break
        except Exception as e:
            logger.warning(f"Error loading talent AI effect: {e}")
        
        # Build full prompt
        prompt = f"""
=== CHARACTER DATA ===
Tu·ªïi: {age}
Gi·ªõi t√≠nh: {gender}
Thi√™n ph√∫: {talent}{f" ({talent_ai_effect})" if talent_ai_effect else ""}
Ch·ªßng t·ªôc: {race}
B·ªëi c·∫£nh: {background}
C√¢u chuy·ªán: {story}

=== CULTIVATION ===
C·∫£nh gi·ªõi: {realm} (Level {realm_level})
Tu vi: {cultivation.get('spiritual_power', 0)}/{cultivation.get('max_spiritual_power', 100)}
Ti·∫øn ƒë·ªô ƒë·ªôt ph√°: {cultivation.get('breakthrough_progress', 0.0)}%

=== ATTRIBUTES ===
{ai_context}

=== PHYSIQUE (TH·ªÇ CH·∫§T) ===
{physique_context}

=== LOCATION ===
{location_context}

=== SECT ===
{sect_context}

=== RACE ===
{race_context}

=== MEMORY ===
{memory_context or "Kh√¥ng c√≥ k√Ω ·ª©c"}

=== WORKING MEMORY ===
{working_memory or "Kh√¥ng c√≥ nhi·ªám v·ª•"}

=== CURRENT ACTION ===
"""
        
        selected_choice_text = ""
        if current_choice is not None:
            choices = character_data.get("choices", [])
            if 0 <= current_choice < len(choices):
                selected_choice_text = choices[current_choice]
                prompt += f"""
=== NG∆Ø·ªúI CH∆†I ƒê√É CH·ªåN ===
L·ª±a ch·ªçn s·ªë {current_choice + 1}: "{selected_choice_text}"

‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è QUAN TR·ªåNG NH·∫§T ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è
Narrative PH·∫¢I m√¥ t·∫£ C·ª§ TH·ªÇ nh·ªØng g√¨ x·∫£y ra khi ng∆∞·ªùi ch∆°i th·ª±c hi·ªán l·ª±a ch·ªçn "{selected_choice_text}".

V√ç D·ª§ C·ª§ TH·ªÇ:
- N·∫øu ch·ªçn "Ti·∫øp t·ª•c tu luy·ªán" ‚Üí M√¥ t·∫£: "B·∫°n ng·ªìi xu·ªëng, nh·∫Øm m·∫Øt, b·∫Øt ƒë·∫ßu ƒëi·ªÅu khi·ªÉn linh kh√≠ trong c∆° th·ªÉ. D√≤ng linh kh√≠ ch·∫£y qua c√°c kinh m·∫°ch, b·∫°n c·∫£m nh·∫≠n ƒë∆∞·ª£c s·ª± tƒÉng tr∆∞·ªüng t·ª´ng ch√∫t m·ªôt. Sau nhi·ªÅu th√°ng tu luy·ªán, tu vi c·ªßa b·∫°n ƒë√£ tƒÉng l√™n..."

- N·∫øu ch·ªçn "ƒêi kh√°m ph√°" ‚Üí M√¥ t·∫£: "B·∫°n quy·∫øt ƒë·ªãnh r·ªùi kh·ªèi n∆°i ·ªü, b∆∞·ªõc ch√¢n ra ngo√†i kh√°m ph√°. B·∫°n ƒëi qua nh·ªØng con ƒë∆∞·ªùng nh·ªè, leo l√™n ƒë·ªìi, xu·ªëng thung l≈©ng. Trong m·ªôt hang ƒë·ªông, b·∫°n ph√°t hi·ªán..."

- N·∫øu ch·ªçn "T√¨m ki·∫øm t√¥ng m√¥n" ‚Üí M√¥ t·∫£: "B·∫°n b·∫Øt ƒë·∫ßu h√†nh tr√¨nh t√¨m ki·∫øm t√¥ng m√¥n. B·∫°n h·ªèi thƒÉm ng∆∞·ªùi d√¢n, ƒëi theo nh·ªØng con ƒë∆∞·ªùng l·ªõn. Sau nhi·ªÅu ng√†y, b·∫°n ƒë·∫øn ƒë∆∞·ª£c c·ªïng m·ªôt t√¥ng m√¥n..."

- N·∫øu ch·ªçn "Ngh·ªâ ng∆°i" ‚Üí M√¥ t·∫£: "B·∫°n quy·∫øt ƒë·ªãnh ngh·ªâ ng∆°i, kh√¥ng tu luy·ªán. B·∫°n ng·ªìi d∆∞·ªõi g·ªëc c√¢y, nh√¨n ng·∫Øm c·∫£nh v·∫≠t xung quanh. Trong l√∫c ngh·ªâ ng∆°i, b·∫°n suy ng·∫´m v·ªÅ..."

KH√îNG ƒê∆Ø·ª¢C vi·∫øt chung chung nh∆∞ "ti·∫øp t·ª•c tu luy·ªán" m√† PH·∫¢I m√¥ t·∫£ C·ª§ TH·ªÇ t·ª´ng h√†nh ƒë·ªông, t·ª´ng b∆∞·ªõc ƒëi, t·ª´ng s·ª± ki·ªán x·∫£y ra.
"""
        else:
            prompt += "Ng∆∞·ªùi ch∆°i ƒëang ch·ªù l·ª±a ch·ªçn.\n"
        
        prompt += f"""
=== INSTRUCTIONS ===
QUAN TR·ªåNG: T·∫°o narrative C·ª§ TH·ªÇ v√† ƒêA D·∫†NG cho nƒÉm th·ª© {age + 1}. KH√îNG ƒë∆∞·ª£c l·∫∑p l·∫°i "nƒÉm X tr√¥i qua m·ªôt c√°ch b√¨nh th∆∞·ªùng".

1. NARRATIVE PH·∫¢I:
   - D·ª∞A V√ÄO L·ª∞A CH·ªåN "{selected_choice_text if selected_choice_text else 'c·ªßa ng∆∞·ªùi ch∆°i'}" ƒë·ªÉ t·∫°o narrative ph√π h·ª£p
   - M√¥ t·∫£ T·ª™NG B∆Ø·ªöC, T·ª™NG H√ÄNH ƒê·ªòNG c·ª• th·ªÉ (b∆∞·ªõc ƒëi, ng·ªìi xu·ªëng, nh·∫Øm m·∫Øt, leo l√™n, xu·ªëng, g·∫∑p g·ª°, n√≥i chuy·ªán...)
   - M√¥ t·∫£ C·∫¢NH V·∫¨T, ƒê·ªäA ƒêI·ªÇM c·ª• th·ªÉ (hang ƒë·ªông, r·ª´ng c√¢y, con ƒë∆∞·ªùng, ng√¥i l√†ng...)
   - M√¥ t·∫£ NG∆Ø·ªúI G·∫∂P, CU·ªòC TR√í CHUY·ªÜN n·∫øu c√≥
   - M√¥ t·∫£ K·∫æT QU·∫¢, THAY ƒê·ªîI c·ª• th·ªÉ (t√¨m ƒë∆∞·ª£c g√¨, h·ªçc ƒë∆∞·ª£c g√¨, tu vi tƒÉng bao nhi√™u...)
   - M·ªói l·ª±a ch·ªçn PH·∫¢I d·∫´n ƒë·∫øn narrative HO√ÄN TO√ÄN KH√ÅC NHAU
   - D√†i √≠t nh·∫•t 5-7 c√¢u, m√¥ t·∫£ chi ti·∫øt t·ª´ng b∆∞·ªõc

2. CHOICES:
   - ƒê∆∞a ra 4-6 l·ª±a ch·ªçn ƒêA D·∫†NG cho nƒÉm ti·∫øp theo
   - M·ªói l·ª±a ch·ªçn ph·∫£i d·∫´n ƒë·∫øn narrative KH√ÅC NHAU
   - Kh√¥ng ƒë∆∞·ª£c l·∫∑p l·∫°i c√°c l·ª±a ch·ªçn gi·ªëng nhau

3. STATE_UPDATES (B·∫ÆT BU·ªòC):
   - PH·∫¢I c·∫≠p nh·∫≠t cultivation (spiritual_power tƒÉng, breakthrough_progress thay ƒë·ªïi)
   - PH·∫¢I c·∫≠p nh·∫≠t resources (spirit_stones, pills, materials thay ƒë·ªïi)
   - PH·∫¢I c·∫≠p nh·∫≠t attributes n·∫øu c√≥ thay ƒë·ªïi
   - M·ªói nƒÉm ph·∫£i c√≥ thay ƒë·ªïi v·ªÅ stats

V√ç D·ª§ NARRATIVE T·ªêT CHO "ƒêI KH√ÅM PH√Å":
"NƒÉm th·ª© 2, b·∫°n quy·∫øt ƒë·ªãnh r·ªùi kh·ªèi l√†ng ƒë·ªÉ kh√°m ph√° th·∫ø gi·ªõi xung quanh. B·∫°n b∆∞·ªõc ƒëi tr√™n con ƒë∆∞·ªùng ƒë·∫•t nh·ªè, ƒëi qua nh·ªØng c√°nh ƒë·ªìng l√∫a xanh m∆∞·ªõt. Sau v√†i gi·ªù ƒëi b·ªô, b·∫°n ƒë·∫øn m·ªôt khu r·ª´ng r·∫≠m. Trong r·ª´ng, b·∫°n nghe th·∫•y ti·∫øng n∆∞·ªõc ch·∫£y. B·∫°n ƒëi theo ti·∫øng n∆∞·ªõc v√† ph√°t hi·ªán ra m·ªôt th√°c n∆∞·ªõc nh·ªè. Ph√≠a sau th√°c n∆∞·ªõc, b·∫°n nh√¨n th·∫•y m·ªôt hang ƒë·ªông ·∫©n khu·∫•t. B·∫°n c·∫©n th·∫≠n b∆∞·ªõc v√†o, trong hang ƒë·ªông t·ªëi tƒÉm, b·∫°n t√¨m th·∫•y m·ªôt vi√™n ƒëan d∆∞·ª£c c·ªï x∆∞a c√≤n s√≥t l·∫°i tr√™n m·ªôt t·∫£ng ƒë√°. Sau khi s·ª≠ d·ª•ng, tu vi c·ªßa b·∫°n tƒÉng l√™n ƒë√°ng k·ªÉ."

V√ç D·ª§ NARRATIVE T·ªêT CHO "TI·∫æP T·ª§C TU LUY·ªÜN":
"NƒÉm th·ª© 2, b·∫°n quy·∫øt ƒë·ªãnh d√†nh to√†n b·ªô th·ªùi gian ƒë·ªÉ tu luy·ªán. M·ªói s√°ng, b·∫°n ng·ªìi xu·ªëng tr√™n t·∫£ng ƒë√° ph·∫≥ng, nh·∫Øm m·∫Øt, b·∫Øt ƒë·∫ßu ƒëi·ªÅu khi·ªÉn linh kh√≠ trong c∆° th·ªÉ. B·∫°n c·∫£m nh·∫≠n d√≤ng linh kh√≠ ch·∫£y qua c√°c kinh m·∫°ch, t·ª´ ƒëan ƒëi·ªÅn l√™n ƒë·ªânh ƒë·∫ßu r·ªìi quay tr·ªü l·∫°i. Sau nhi·ªÅu th√°ng tu luy·ªán kh√¥ng ng·ª´ng ngh·ªâ, b·∫°n ƒë√£ c√≥ th·ªÉ ƒëi·ªÅu khi·ªÉn linh kh√≠ m·ªôt c√°ch thu·∫ßn th·ª•c h∆°n. Tu vi c·ªßa b·∫°n tƒÉng l√™n ƒë√°ng k·ªÉ, ƒë·∫°t ƒë∆∞·ª£c Luy·ªán Kh√≠ K·ª≥ c·∫•p 2. B·∫°n c·∫£m th·∫•y s·ª©c m·∫°nh trong c∆° th·ªÉ tƒÉng l√™n r√µ r·ªát."

V√ç D·ª§ NARRATIVE T·ªÜ (KH√îNG ƒê∆Ø·ª¢C):
"NƒÉm 2 tr√¥i qua m·ªôt c√°ch b√¨nh th∆∞·ªùng."
"Ng∆∞·ªùi Tu Ti√™n ti·∫øp t·ª•c tu luy·ªán t·∫°i L√†ng Thanh Th·ªßy. V·ªõi thi√™n ph√∫ Thi√™n Linh CƒÉn, b·∫°n ƒë√£ c√≥ nh·ªØng ti·∫øn b·ªô trong vi·ªác c·∫£m nh·∫≠n v√† ƒëi·ªÅu khi·ªÉn linh kh√≠. M·ªói ng√†y tr√¥i qua ƒë·ªÅu mang l·∫°i nh·ªØng hi·ªÉu bi·∫øt m·ªõi v·ªÅ th·∫ø gi·ªõi tu ti√™n."

Format JSON:
{{
    "narrative": "M√¥ t·∫£ C·ª§ TH·ªÇ v√† ƒêA D·∫†NG v·ªÅ nh·ªØng g√¨ x·∫£y ra trong nƒÉm...",
    "choices": ["L·ª±a ch·ªçn 1", "L·ª±a ch·ªçn 2", "L·ª±a ch·ªçn 3", "L·ª±a ch·ªçn 4"],
    "action_intent": "YEAR_PROGRESS",
    "state_updates": {{
        "age": {age + 1},
        "cultivation": {{
            "spiritual_power": <tƒÉng l√™n>,
            "breakthrough_progress": <thay ƒë·ªïi>,
            "realm_level": <c√≥ th·ªÉ tƒÉng>
        }},
        "resources": {{
            "spirit_stones": <thay ƒë·ªïi>,
            "pills": {{"<t√™n ƒëan>": <s·ªë l∆∞·ª£ng>}},
            "materials": {{"<t√™n v·∫≠t li·ªáu>": <s·ªë l∆∞·ª£ng>}}
        }},
        "attributes": {{
            <c·∫≠p nh·∫≠t n·∫øu c√≥>
        }}
    }}
}}
"""
        
        return prompt
    
    def process_character_creation(
        self,
        character_data: Dict[str, Any],
        memory_context: Optional[str] = None,
        working_memory: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Process character creation (age 0) - different from year progress
        """
        gender = character_data.get("gender", "Nam")
        talent = character_data.get("talent", "B√¨nh th∆∞·ªùng")
        race = character_data.get("race", "Ng∆∞·ªùi")
        background = character_data.get("background", "N√¥ng d√¢n")
        location_name = character_data.get("location_name", "l√†ng qu√™")
        
        prompt = f"""
=== CHARACTER CREATION ===
B·∫°n ƒëang t·∫°o c√¢u chuy·ªán kh·ªüi ƒë·∫ßu cho m·ªôt nh√¢n v·∫≠t tu ti√™n M·ªöI SINH (0 tu·ªïi).

Th√¥ng tin nh√¢n v·∫≠t:
- Gi·ªõi t√≠nh: {gender}
- Thi√™n ph√∫: {talent}
- Ch·ªßng t·ªôc: {race}
- B·ªëi c·∫£nh: {background}
- N∆°i sinh: {location_name}

QUAN TR·ªåNG:
- Nh√¢n v·∫≠t M·ªöI SINH (0 tu·ªïi), ch∆∞a th·ªÉ tu luy·ªán
- T·∫°o c√¢u chuy·ªán v·ªÅ th·ªùi th∆° ·∫•u, gia ƒë√¨nh, m√¥i tr∆∞·ªùng s·ªëng
- M√¥ t·∫£ thi√™n ph√∫ {talent} th·ªÉ hi·ªán nh∆∞ th·∫ø n√†o t·ª´ nh·ªè
- T·∫°o t√™n nh√¢n v·∫≠t ph√π h·ª£p v·ªõi b·ªëi c·∫£nh {background}
- ƒê∆∞a ra 4-6 l·ª±a ch·ªçn cho nƒÉm ƒë·∫ßu ti√™n (1 tu·ªïi) - nh·ªØng ho·∫°t ƒë·ªông ph√π h·ª£p v·ªõi tr·∫ª nh·ªè

V√ç D·ª§ NARRATIVE T·ªêT:
"B·∫°n ƒë∆∞·ª£c sinh ra trong m·ªôt gia ƒë√¨nh {background} t·∫°i {location_name}. Ngay t·ª´ khi c√≤n nh·ªè, v·ªõi thi√™n ph√∫ {talent}, b·∫°n ƒë√£ th·ªÉ hi·ªán nh·ªØng d·∫•u hi·ªáu ƒë·∫∑c bi·ªát - c√≥ th·ªÉ c·∫£m nh·∫≠n ƒë∆∞·ª£c d√≤ng linh kh√≠ nh·∫π nh√†ng xung quanh, d√π ch∆∞a hi·ªÉu ƒë√≥ l√† g√¨. Gia ƒë√¨nh b·∫°n nh·∫≠n th·∫•y ti·ªÅm nƒÉng v√† b·∫Øt ƒë·∫ßu chu·∫©n b·ªã cho b·∫°n con ƒë∆∞·ªùng tu ti√™n t·ª´ s·ªõm."

Format JSON:
{{
    "narrative": "C√¢u chuy·ªán v·ªÅ th·ªùi th∆° ·∫•u, KH√îNG c√≥ tu luy·ªán v√¨ m·ªõi sinh...",
    "character_name": "T√™n nh√¢n v·∫≠t ph√π h·ª£p",
    "choices": ["L·ª±a ch·ªçn 1", "L·ª±a ch·ªçn 2", "L·ª±a ch·ªçn 3", "L·ª±a ch·ªçn 4"],
    "action_intent": "CHARACTER_CREATION",
    "state_updates": {{
        "age": 0
    }}
}}
"""
        
        try:
            response = self.model.generate_content(prompt)
            text = response.text.strip()
            
            print(f"üìù Character Creation AI Response (first 200 chars): {text[:200]}...")
            
            # Parse JSON
            try:
                if "```json" in text:
                    text = text.split("```json")[1].split("```")[0].strip()
                elif "```" in text:
                    text = text.split("```")[1].split("```")[0].strip()
                
                data = json.loads(text)
                
                # Validate
                from schemas import CharacterCreationResponse
                try:
                    response_obj = CharacterCreationResponse(**data)
                    result = response_obj.dict()
                    
                    # Ensure character_name exists
                    if "character_name" not in result or not result["character_name"]:
                        result["character_name"] = "Ng∆∞·ªùi Tu Ti√™n"
                    
                    return result
                except Exception as e:
                    print(f"‚ö†Ô∏è Character creation schema error: {e}")
                    # Use partial data if available
                    return {
                        "narrative": data.get("narrative", ""),
                        "character_name": data.get("character_name", "Ng∆∞·ªùi Tu Ti√™n"),
                        "choices": data.get("choices", ["Ti·∫øp t·ª•c l·ªõn l√™n", "Quan s√°t th·∫ø gi·ªõi xung quanh", "Ch∆°i v·ªõi c√°c tr·∫ª kh√°c", "Nghe k·ªÉ chuy·ªán tu ti√™n"]),
                        "action_intent": "CHARACTER_CREATION",
                        "state_updates": {"age": 0}
                    }
            except json.JSONDecodeError as e:
                print(f"‚ö†Ô∏è Character creation JSON parse error: {e}")
                print(f"Raw text (first 1000 chars): {text[:1000]}")
                print(f"Raw text length: {len(text)}")
                
                # Try to extract and fix incomplete JSON
                import re
                # Try to find JSON object and fix if incomplete
                if "```json" in text or "```" in text:
                    # Extract from markdown
                    if "```json" in text:
                        extracted = text.split("```json")[1].split("```")[0].strip()
                    else:
                        extracted = text.split("```")[1].split("```")[0].strip()
                else:
                    extracted = text.strip()
                
                # Try to fix incomplete JSON by finding the last complete object
                try:
                    # Find the last complete closing brace
                    last_brace = extracted.rfind('}')
                    if last_brace > 0:
                        # Try to parse up to the last complete brace
                        candidate = extracted[:last_brace + 1]
                        # Try to find the opening brace
                        first_brace = candidate.find('{')
                        if first_brace >= 0:
                            candidate = candidate[first_brace:]
                            data = json.loads(candidate)
                            print(f"‚úÖ Fixed incomplete JSON by truncating to last complete object")
                        else:
                            raise
                    else:
                        raise
                except:
                    # If all else fails, use fallback
                    print(f"‚ùå Could not fix JSON, using fallback")
                    raise
        
        except Exception as e:
            print(f"‚ùå Character creation AI error: {e}")
            import traceback
            traceback.print_exc()
            # Create appropriate fallback for character creation
            return {
                "narrative": f"B·∫°n ƒë∆∞·ª£c sinh ra trong m·ªôt gia ƒë√¨nh {background} t·∫°i {location_name}. V·ªõi thi√™n ph√∫ {talent}, b·∫°n ƒë√£ th·ªÉ hi·ªán nh·ªØng d·∫•u hi·ªáu ƒë·∫∑c bi·ªát ngay t·ª´ khi c√≤n nh·ªè, d√π ch∆∞a hi·ªÉu v·ªÅ th·∫ø gi·ªõi tu ti√™n.",
                "character_name": "Ng∆∞·ªùi Tu Ti√™n",
                "choices": [
                    "L·ªõn l√™n v√† quan s√°t th·∫ø gi·ªõi",
                    "Nghe k·ªÉ chuy·ªán v·ªÅ tu ti√™n",
                    "Ch∆°i v·ªõi c√°c tr·∫ª kh√°c trong l√†ng",
                    "Quan s√°t ng∆∞·ªùi l·ªõn tu luy·ªán"
                ],
                "action_intent": "CHARACTER_CREATION",
                "state_updates": {"age": 0}
            }
    
    def _parse_response(self, text: str, character_data: Dict[str, Any]) -> Dict[str, Any]:
        """Parse AI response v·ªõi fallback"""
        # Try to extract JSON
        try:
            original_text = text
            # Remove markdown code blocks if present
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            # Try to find JSON object in text - improved parsing
            import re
            # First try to extract JSON from markdown code blocks
            if "```json" in text or "```" in text:
                # Already extracted above, try parsing directly
                try:
                    data = json.loads(text)
                except:
                    # If that fails, try to find the largest JSON object
                    # Match balanced braces
                    brace_count = 0
                    start_idx = -1
                    best_match = None
                    best_length = 0
                    
                    for i, char in enumerate(text):
                        if char == '{':
                            if brace_count == 0:
                                start_idx = i
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0 and start_idx != -1:
                                candidate = text[start_idx:i+1]
                                if len(candidate) > best_length:
                                    try:
                                        json.loads(candidate)  # Test if valid
                                        best_match = candidate
                                        best_length = len(candidate)
                                    except:
                                        pass
                    
                    if best_match:
                        data = json.loads(best_match)
                    else:
                        raise json.JSONDecodeError("No valid JSON found", text, 0)
            else:
                # No markdown, try parsing whole text
                data = json.loads(text)
            
            # Validate v·ªõi Pydantic schema
            try:
                response = CultivationLLMResponse(**data)
                result = response.dict()
                
                # Ensure state_updates exists and has minimum required fields
                if "state_updates" not in result or not result["state_updates"]:
                    result["state_updates"] = {}
                
                # Ensure age is updated
                current_age = character_data.get("age", 0)
                if "age" not in result["state_updates"]:
                    result["state_updates"]["age"] = current_age + 1
                
                # Ensure cultivation updates exist (at minimum, spiritual_power should increase)
                if "cultivation" not in result["state_updates"]:
                    current_cultivation = character_data.get("cultivation", {})
                    current_sp = current_cultivation.get("spiritual_power", 0)
                    current_max_sp = current_cultivation.get("max_spiritual_power", 100)
                    result["state_updates"]["cultivation"] = {
                        "spiritual_power": min(current_sp + 10, current_max_sp),  # Small progress
                        "breakthrough_progress": current_cultivation.get("breakthrough_progress", 0.0) + 1.0
                    }
                
                return result
            except Exception as e:
                print(f"‚ö†Ô∏è Schema validation error: {e}")
                import traceback
                traceback.print_exc()
                print(f"‚ö†Ô∏è Partial data available: {data}")
                print(f"‚ö†Ô∏è Data keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
                
                # Try to use partial data if it has narrative
                if data and isinstance(data, dict) and data.get("narrative") and len(data.get("narrative", "")) > 50:
                    print(f"‚úÖ Using partial data narrative (bypassing schema validation): {data.get('narrative')[:200]}...")
                    # Ensure state_updates exists
                    state_updates = data.get("state_updates", {})
                    if not state_updates:
                        current_age = character_data.get("age", 0)
                        state_updates = {"age": current_age + 1}
                    
                    return {
                        "narrative": data.get("narrative", ""),
                        "choices": data.get("choices", []),
                        "action_intent": data.get("action_intent", "YEAR_PROGRESS"),
                        "state_updates": state_updates
                    }
                
                print(f"‚ùå Cannot use partial data, using fallback")
                return self._create_fallback_response(character_data, data)
        
        except json.JSONDecodeError as e:
            print(f"‚ö†Ô∏è JSON parse error: {e}")
            print(f"‚ö†Ô∏è Raw text that failed to parse (first 1000 chars): {text[:1000]}...")
            print(f"‚ö†Ô∏è Raw text length: {len(text)}")
            
            # Try to extract JSON manually if it's embedded in text
            import re
            json_match = re.search(r'\{[^{}]*"narrative"[^{}]*\}', text, re.DOTALL)
            if json_match:
                try:
                    extracted_json = json_match.group(0)
                    print(f"‚úÖ Found JSON-like structure, trying to parse: {extracted_json[:200]}...")
                    data = json.loads(extracted_json)
                    if data.get("narrative") and len(data.get("narrative", "")) > 50:
                        print(f"‚úÖ Successfully extracted narrative from text")
                        return {
                            "narrative": data.get("narrative", ""),
                            "choices": data.get("choices", []),
                            "action_intent": data.get("action_intent", "YEAR_PROGRESS"),
                            "state_updates": data.get("state_updates", {"age": character_data.get("age", 0) + 1})
                        }
                except:
                    pass
            
            import traceback
            traceback.print_exc()
            return self._create_fallback_response(character_data)
    
    def _create_fallback_response(
        self,
        character_data: Dict[str, Any],
        partial_data: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """T·∫°o fallback response khi AI fail"""
        age = character_data.get("age", 0)
        name = character_data.get("name", "Ng∆∞·ªùi Tu Ti√™n")
        talent = character_data.get("talent", "B√¨nh th∆∞·ªùng")
        location_name = character_data.get("location_name", "l√†ng qu√™")
        
        if partial_data:
            # Use partial data if available
            narrative = partial_data.get("narrative", "")
            choices = partial_data.get("choices", [])
            
            # If narrative is empty or generic, create a better one
            if not narrative or "tr√¥i qua m·ªôt c√°ch b√¨nh th∆∞·ªùng" in narrative or "tr√¥i qua" in narrative.lower():
                if age == 0:
                    narrative = f"{name} ƒë∆∞·ª£c sinh ra trong m·ªôt gia ƒë√¨nh t·∫°i {location_name}. V·ªõi thi√™n ph√∫ {talent}, b·∫°n ƒë√£ th·ªÉ hi·ªán nh·ªØng d·∫•u hi·ªáu ƒë·∫∑c bi·ªát ngay t·ª´ khi c√≤n nh·ªè, d√π ch∆∞a hi·ªÉu v·ªÅ th·∫ø gi·ªõi tu ti√™n."
                else:
                    narrative = f"{name} ti·∫øp t·ª•c h√†nh tr√¨nh tu ti√™n. V·ªõi thi√™n ph√∫ {talent}, b·∫°n ƒë√£ c√≥ nh·ªØng ti·∫øn b·ªô nh·ªè trong vi·ªác c·∫£m nh·∫≠n linh kh√≠ xung quanh t·∫°i {location_name}. M·ªói ng√†y tr√¥i qua ƒë·ªÅu mang l·∫°i nh·ªØng b√†i h·ªçc m·ªõi v·ªÅ th·∫ø gi·ªõi tu ti√™n."
        else:
            # Create a more interesting fallback narrative
            if age == 0:
                narrative = f"{name} ƒë∆∞·ª£c sinh ra trong m·ªôt gia ƒë√¨nh t·∫°i {location_name}. V·ªõi thi√™n ph√∫ {talent}, b·∫°n ƒë√£ th·ªÉ hi·ªán nh·ªØng d·∫•u hi·ªáu ƒë·∫∑c bi·ªát ngay t·ª´ khi c√≤n nh·ªè - c√≥ th·ªÉ c·∫£m nh·∫≠n ƒë∆∞·ª£c d√≤ng linh kh√≠ nh·∫π nh√†ng xung quanh, d√π ch∆∞a hi·ªÉu ƒë√≥ l√† g√¨. Gia ƒë√¨nh b·∫°n nh·∫≠n th·∫•y ti·ªÅm nƒÉng v√† b·∫Øt ƒë·∫ßu chu·∫©n b·ªã cho b·∫°n con ƒë∆∞·ªùng tu ti√™n t·ª´ s·ªõm."
            else:
                narrative = f"{name} ti·∫øp t·ª•c tu luy·ªán t·∫°i {location_name}. V·ªõi thi√™n ph√∫ {talent}, b·∫°n ƒë√£ c√≥ nh·ªØng ti·∫øn b·ªô trong vi·ªác c·∫£m nh·∫≠n v√† ƒëi·ªÅu khi·ªÉn linh kh√≠. M·ªói ng√†y tr√¥i qua ƒë·ªÅu mang l·∫°i nh·ªØng hi·ªÉu bi·∫øt m·ªõi v·ªÅ th·∫ø gi·ªõi tu ti√™n."
            
            choices = [
                "Ti·∫øp t·ª•c tu luy·ªán",
                "ƒêi kh√°m ph√° khu v·ª±c xung quanh",
                "T√¨m ki·∫øm t√¥ng m√¥n ƒë·ªÉ gia nh·∫≠p",
                "Ngh·ªâ ng∆°i v√† suy ng·∫´m"
            ]
        
        # Ensure 4-6 choices
        while len(choices) < 4:
            choices.append(f"L·ª±a ch·ªçn {len(choices) + 1}")
        choices = choices[:6]
        
        # Get current cultivation state
        cultivation = character_data.get("cultivation", {})
        current_sp = cultivation.get("spiritual_power", 0)
        current_max_sp = cultivation.get("max_spiritual_power", 100)
        current_bp = cultivation.get("breakthrough_progress", 0.0)
        
        return {
            "narrative": narrative,
            "choices": choices,
            "action_intent": "YEAR_PROGRESS",
            "state_updates": {
                "age": age + 1,
                "cultivation": {
                    "spiritual_power": min(current_sp + 10, current_max_sp),  # Small progress
                    "breakthrough_progress": min(current_bp + 1.0, 100.0)
                },
                "resources": {
                    "spirit_stones": character_data.get("resources", {}).get("spirit_stones", 0) + 5  # Small gain
                }
            }
        }
    
    async def plan_action(self, prompt: str) -> Dict[str, Any]:
        """
        AI Planning method cho AIPlannerSystem
        
        Returns:
            {
                "thought_process": str,
                "emotional_state": str,
                "decision": {...}
            }
        """
        try:
            response = self.model.generate_content(prompt)
            text = response.text.strip()
            
            # Parse JSON
            if "```json" in text:
                text = text.split("```json")[1].split("```")[0].strip()
            elif "```" in text:
                text = text.split("```")[1].split("```")[0].strip()
            
            return json.loads(text)
        
        except Exception as e:
            print(f"‚ùå AI Planning error: {e}")
            return {
                "thought_process": "Kh√¥ng c√≥ suy nghƒ© ƒë·∫∑c bi·ªát",
                "emotional_state": "Calm",
                "decision": {
                    "action_type": "rest",
                    "target_id": None,
                    "dialogue_content": None
                }
            }
    
    async def create_summary(self, conversations: List[str]) -> str:
        """
        T·∫°o summary t·ª´ conversations (cho Rolling Summary)
        """
        prompt = f"""
T√≥m t·∫Øt c√°c cu·ªôc h·ªôi tho·∫°i sau ƒë√¢y, t·∫≠p trung v√†o:
- Thay ƒë·ªïi quan h·ªá
- Th√¥ng tin m·ªõi h·ªçc ƒë∆∞·ª£c
- L·ªùi h·ª©a h·∫πn
- S·ª± ki·ªán quan tr·ªçng

Conversations:
{chr(10).join(conversations)}

T√≥m t·∫Øt ng·∫Øn g·ªçn (20-30 t·ª´):
"""
        
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            print(f"‚ùå Summary error: {e}")
            return f"T√≥m t·∫Øt {len(conversations)} cu·ªôc h·ªôi tho·∫°i"
