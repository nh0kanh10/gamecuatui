# üöÄ Quick Start: Benchmark Testing

## B∆∞·ªõc 1: Setup m√¥i tr∆∞·ªùng (ch·ªâ ch·∫°y 1 l·∫ßn)

```bash
# Ch·∫°y script t·ª± ƒë·ªông
setup_benchmark.bat
```

Ho·∫∑c l√†m th·ªß c√¥ng:
```bash
# T·∫°o virtual environment
python -m venv venv

# Activate
venv\Scripts\activate

# C√†i dependencies
pip install -r benchmarks\requirements.txt
```

---

## B∆∞·ªõc 2: Download models

```bash
# Ch·∫°y script download t·ª± ƒë·ªông
python benchmarks\download_models.py
```

Script s·∫Ω h·ªèi b·∫°n ch·ªçn:
- **Option 1**: T·∫£i t·∫•t c·∫£ (khuy·∫øn ngh·ªã n·∫øu ƒë·ªß dung l∆∞·ª£ng)
- **Option 2**: Ch·ªâ t·∫£i Phi-3-mini (nhanh nh·∫•t, ~2.4GB)
- **Option 3**: Ch·ªçn t·ª´ng model

**Models ƒë∆∞·ª£c download:**
- `Phi-3-mini-4k-q4.gguf` (2.4GB) - Khuy·∫øn ngh·ªã
- `llama-3.2-3b-q4.gguf` (1.9GB) - M·ªõi nh·∫•t
- `mistral-7b-q4.gguf` (4.4GB) - So s√°nh

---

## B∆∞·ªõc 3: Ch·∫°y benchmark

### Option A: Test ƒë∆°n l·∫ª (nhanh)

```bash
# Test CPU-only v·ªõi Phi-3
python benchmarks\benchmark_inference.py ^
  --model models\phi-3-mini-4k-q4.gguf ^
  --n_gpu_layers 0 ^
  --test_name Phi3_CPU

# Test v·ªõi GPU (8 layers)
python benchmarks\benchmark_inference.py ^
  --model models\phi-3-mini-4k-q4.gguf ^
  --n_gpu_layers 8 ^
  --test_name Phi3_8GPU
```

### Option B: Test t·∫•t c·∫£ configs (t·ª± ƒë·ªông)

```bash
# Ch·∫°y full sweep (5-10 ph√∫t/test)
python benchmarks\benchmark_sweep.py
```

Script s·∫Ω:
- Test t·∫•t c·∫£ models v·ªõi c√°c configs kh√°c nhau
- T·ª± ƒë·ªông l∆∞u k·∫øt qu·∫£
- T·∫°o b√°o c√°o so s√°nh

---

## B∆∞·ªõc 4: Xem k·∫øt qu·∫£

K·∫øt qu·∫£ ƒë∆∞·ª£c l∆∞u trong:
```
benchmarks/results/
‚îú‚îÄ‚îÄ Phi3_CPU_20251202_164830.json
‚îú‚îÄ‚îÄ Phi3_8GPU_20251202_165245.json
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ COMPARISON_REPORT.md   ‚Üê B√°o c√°o so s√°nh
```

### M·ªü b√°o c√°o so s√°nh:
```bash
code benchmarks\results\COMPARISON_REPORT.md
```

### ƒê·ªçc JSON k·∫øt qu·∫£:
```bash
python -m json.tool benchmarks\results\Phi3_CPU_*.json
```

---

## C√°c th√¥ng s·ªë quan tr·ªçng

| Metric | Target | √ù nghƒ©a |
|--------|--------|---------|
| **tokens/second** | ‚â•3 t/s | T·ªëc ƒë·ªô sinh text - c√†ng cao c√†ng t·ªët |
| **avg_latency_ms** | <300ms | ƒê·ªô tr·ªÖ m·ªói token - c√†ng th·∫•p c√†ng t·ªët |
| **max_vram_mb** | <3500MB | VRAM s·ª≠ d·ª•ng - ph·∫£i < 4GB |
| **max_ram_mb** | <20GB | RAM s·ª≠ d·ª•ng - ƒë·ªÉ l·∫°i cho OS |

---

## Gi·∫£i th√≠ch k·∫øt qu·∫£

### ‚úÖ Excellent (‚â•4 t/s)
‚Üí D√πng l√†m model ch√≠nh cho real-time gameplay

### ‚úÖ Good (3-4 t/s)
‚Üí Ch·∫•p nh·∫≠n ƒë∆∞·ª£c cho text adventure

### ‚ö†Ô∏è Marginal (2-3 t/s)
‚Üí C√≥ th·ªÉ d√πng cho "lazy inflation" (offline generation)

### ‚ùå Poor (<2 t/s)
‚Üí Qu√° ch·∫≠m, kh√¥ng s·ª≠ d·ª•ng

---

## Troubleshooting

### L·ªói: `ImportError: DLL load failed`
**Nguy√™n nh√¢n**: llama-cpp-python kh√¥ng build ƒë∆∞·ª£c v·ªõi CUDA

**Gi·∫£i ph√°p**: D√πng CPU-only build
```bash
pip uninstall llama-cpp-python
pip install llama-cpp-python --no-cache-dir
```

### L·ªói: `CUDA out of memory`
**Nguy√™n nh√¢n**: Qu√° nhi·ªÅu layers tr√™n GPU

**Gi·∫£i ph√°p**: Gi·∫£m `--n_gpu_layers`
```bash
# Thay v√¨ 8, d√πng 4
python benchmarks\benchmark_inference.py --model models\phi-3-mini-4k-q4.gguf --n_gpu_layers 4 --test_name Phi3_4GPU
```

### T·ªëc ƒë·ªô qu√° ch·∫≠m (<1 t/s)
**Ki·ªÉm tra**:
1. ƒê√∫ng s·ªë threads: `--n_threads 8` (= s·ªë threads v·∫≠t l√Ω)
2. Kh√¥ng ch·∫°y app kh√°c n·∫∑ng
3. Laptop kh√¥ng ·ªü ch·∫ø ƒë·ªô ti·∫øt ki·ªám pin

---

## Next Steps sau khi c√≥ k·∫øt qu·∫£

1. ‚úÖ Ch·ªçn model t·ªët nh·∫•t t·ª´ `COMPARISON_REPORT.md`
2. ‚úÖ Update `docs/architecture/ARCHITECTURE.md` v·ªõi con s·ªë th·ª±c t·∫ø
3. ‚úÖ Quy·∫øt ƒë·ªãnh chi·∫øn l∆∞·ª£c:
   - CPU-only n·∫øu GPU kh√¥ng gi√∫p ƒë∆∞·ª£c g√¨
   - Hybrid n·∫øu GPU tƒÉng t·ªëc ƒë√°ng k·ªÉ
4. ‚û°Ô∏è B·∫Øt ƒë·∫ßu implement game engine v·ªõi config ƒë√£ ch·ªçn

---

## Example Output

```
üî¨ Benchmark: Phi3_CPU
============================================================
Model: phi-3-mini-4k-q4.gguf
Config: n_gpu_layers=0, n_ctx=2048, n_threads=8
============================================================

üß™ Test: Short Context
   Prompt length: 53 chars
   ‚úÖ Tokens: 100 | Speed: 4.23 t/s | Latency: 236ms
   VRAM: 450MB | RAM: 3800MB

üìä SUMMARY: Phi3_CPU
============================================================
Average Speed:    4.15 tokens/second
Average Latency:  241 ms/token
Peak VRAM:        450 MB
Peak RAM:         3850 MB

üéØ VERDICT:
   ‚úÖ EXCELLENT - Suitable for real-time text adventure
```
